{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "import Utils\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    y_data=data.iloc[:,-1]\n",
    "    X_data=data.iloc[:,:-1]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,random_state=100,test_size=0.3)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_index(y_true,y_predict):\n",
    "    mae_score=mean_absolute_error(y_true,y_predict)\n",
    "    rmse_score=math.sqrt(mean_squared_error(y_true,y_predict))\n",
    "    r2_score_1=r2_score(y_true,y_predict)\n",
    "    #print(\"mae_score:%s\\nrmse_score:%s\\nr2_score:%s\"%(mae_score,rmse_score,r2_score_1))\n",
    "    return mae_score,rmse_score,r2_score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制学习曲线\n",
    "def plot_learning_curve(algo,num,X_train,X_test,y_train,y_test):\n",
    "    if len(X_train.shape)==1:\n",
    "        X_train=[[x] for x in X_train]\n",
    "        X_test=[[x] for x in X_test]\n",
    "    train_score=[]\n",
    "    test_score=[]\n",
    "    for i in range(1,len(X_train)+1):\n",
    "        if i%10==0:\n",
    "            algo.fit(X_train[:i],y_train[:i])\n",
    "            y_train_predict = algo.predict(X_train[:i])\n",
    "            train_score.append(mean_absolute_error(y_train[:i],y_train_predict))\n",
    "\n",
    "            y_test_predict=algo.predict(X_test)\n",
    "            test_score.append(mean_absolute_error(y_test,y_test_predict))\n",
    "    plt.xlabel(\"Train num\")\n",
    "    plt.ylabel(\"mae score\")\n",
    "    plt.title(\"feature number:%s\"%num)\n",
    "    plt.plot([i for i in range(1,len(train_score)+1)],np.sqrt(train_score),label=\"train\")\n",
    "    plt.plot([i for i in range(1,len(train_score)+1)],np.sqrt(test_score),label=\"test\")\n",
    "    plt.legend()\n",
    "    #指定X轴和y轴的长度，X轴从0到len(X_train)+1,y轴从0到4\n",
    "    plt.axis([0,len(train_score)+1,0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(all_data):\n",
    "    train_data=all_data[all_data['type']=='train'].drop(['type'],axis=1)\n",
    "    test_data=all_data[all_data['type']=='test'].drop(['type','target'],axis=1)\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validate_data(train_data,test_size,random_state):\n",
    "    X=train_data.iloc[:,:-1]\n",
    "    y=train_data['target']\n",
    "    X_train,X_validate,y_train,y_validate=train_test_split(X,y,test_size=test_size,random_state=random_state)\n",
    "    return X_train,X_validate,y_train,y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "data_path='./data/zhengqi_train.txt'\n",
    "o_data=pd.read_csv(data_path,sep='\\t')\n",
    "#读取测试数据\n",
    "test_path='./data/zhengqi_test.txt'\n",
    "test_data=pd.read_csv(test_path,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看测试数据集和训练集的数据分布是否相同，去除掉不同分布的数据特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并训练集与测试集\n",
    "o_data['type']='train'\n",
    "test_data['type']='test'\n",
    "all_data=pd.concat([o_data,test_data])\n",
    "#绘制训练集与测试集的分布图\n",
    "for feature in all_data.columns[:-2]:\n",
    "    all_data[all_data['type']=='train'][feature].plot(kind='kde')\n",
    "    all_data[all_data['type']=='test'][feature].plot(kind='kde')\n",
    "    plt.title(feature)\n",
    "    plt.legend(['train','test'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除掉分布不一样的特征数据 \n",
    "#通过观察上述分布图发现v11,v13,v14,v17,v19,v2,v21,v35,v22,v27,v5,v9\n",
    "#删除掉分布不一样的特征，然后对比模型的准确度\n",
    "#自己挑的：'V11','V13','V14','V17','V19','V2','V21','V35','V22','V27','V5','V9' 提交结果：0.1350\n",
    "#论坛中的：\"V5\",\"V9\",\"V11\",\"V17\",\"V22\",\"V28\" 提交结果：0.1361\n",
    "drop_feature_list=['V11','V13','V14','V17','V19','V2','V21','V35','V22','V27','V5','V9']\n",
    "add_drop_feature=[]\n",
    "for drop_feature in drop_feature_list:\n",
    "    add_drop_feature.append(drop_feature)\n",
    "    all_data_drop=all_data.drop(labels=add_drop_feature,axis=1)\n",
    "    train_data_drop=all_data_drop[all_data_drop['type']=='train'].drop(labels=['type'],axis=1)\n",
    "    X_train,X_test,y_train,y_test=split_data(train_data_drop)\n",
    "    xgb_reg=XGBRegressor(max_depth=8,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "    xgb_reg.fit(X_train,y_train)\n",
    "    y_predict=xgb_reg.predict(X_test)\n",
    "    mae_score,rmse_score,r2_score_1=get_evaluation_index(y_test,y_predict)\n",
    "    plot_learning_curve(xgb_reg,len(X_train.columns),X_train,X_test,y_train,y_test)\n",
    "    print(\"drop feature:%s\\n mae:%s\\t rmse:%s\\t r2:%s\\n\"%([feature for feature in add_drop_feature],mae_score,rmse_score,r2_score_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存drop_feature之后的结果\n",
    "all_data_drop.to_csv('./re/all_data_drop.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_drop_1=pd.read_csv('./re/all_data_drop.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_drop=all_data_drop[all_data_drop['type']=='test'].drop(['type','target'],axis=1)\n",
    "y_predict=xgb_reg.predict(test_data_drop)\n",
    "y_predict_df=pd.DataFrame(y_predict)\n",
    "y_predict_df.to_csv('./re/y_predict_1.txt',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过皮尔逊相关系数 去掉相关性弱的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=all_data_drop_1[all_data_drop_1['type']=='train'].drop(['type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出相关程度\n",
    "plt.figure(figsize=(20, 16))  # 指定绘图对象宽度和高度\n",
    "colnm = train_data.columns.tolist()  # 列表头\n",
    "pearson_corr = train_data[colnm].corr(method=\"pearson\")  # 相关系数矩阵，即给出了任意两个变量之间的相关系数\n",
    "mask = np.zeros_like(pearson_corr, dtype=np.bool)  # 构造与mcorr同维数矩阵 为bool型\n",
    "mask[np.triu_indices_from(mask)] = True  # 角分线右侧为True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)  # 返回matplotlib colormap对象\n",
    "\n",
    "g = sns.heatmap(pearson_corr, mask=mask, cmap=cmap, square=True, annot=True, fmt='0.2f')  # 热力图（看两两相似度）\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出相关程度\n",
    "plt.figure(figsize=(20, 16))  # 指定绘图对象宽度和高度\n",
    "colnm = train_data.columns.tolist()  # 列表头\n",
    "spearman_corr = train_data[colnm].corr(method=\"spearman\")  # 相关系数矩阵，即给出了任意两个变量之间的相关系数\n",
    "mask = np.zeros_like(spearman_corr, dtype=np.bool)  # 构造与mcorr同维数矩阵 为bool型\n",
    "mask[np.triu_indices_from(mask)] = True  # 角分线右侧为True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)  # 返回matplotlib colormap对象\n",
    "g = sns.heatmap(spearman_corr, mask=mask, cmap=cmap, square=True, annot=True, fmt='0.2f')  # 热力图（看两两相似度）\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=spearman_corr['target']\n",
    "s2=pearson_corr['target']\n",
    "com_between_corr=pd.merge(left=s1,right=s2,on=s1.index).set_index('key_0').rename(columns={'target_x':'spearman_corr','target_y':'pearson_corr'})\n",
    "com_between_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 分别根据pearson 和spearman 相关系数去除无用特征\n",
    "#首先设置阈值为0.1，去除相关性小于0.1的特征\n",
    "thresholding=0.1\n",
    "drop_feature_by_spearman=com_between_corr[np.abs(com_between_corr['spearman_corr'])<=thresholding].index\n",
    "drop_feature_by_pearson=com_between_corr[np.abs(com_between_corr['pearson_corr'])<=thresholding].index\n",
    "print(\"spearman:%s\"%drop_feature_by_pearson)\n",
    "print(\"pearson:%s\"%drop_feature_by_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drop_feature_by_corr(data,thresholding=0.1,corr_name='spearman'):\n",
    "    train_data=data[data['type']=='train'].drop(['type'],axis=1)\n",
    "    corr = train_data[colnm].corr(method=corr_name)  \n",
    "    s1=corr['target']\n",
    "    drop_feature=s1[np.abs(s1)<=thresholding].index\n",
    "    return drop_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data_drop_corr(data,drop_feature):\n",
    "    all_data_drop_feature_by_corr=data.drop(labels=drop_feature,axis=1)\n",
    "    train_data_drop=all_data_drop_feature_by_corr[all_data_drop_feature_by_corr['type']=='train'].drop(labels=['type'],axis=1)\n",
    "    test_data_drop=all_data_drop_feature_by_corr[all_data_drop_feature_by_corr['type']=='test'].drop(labels=['type','target'],axis=1)\n",
    "    return all_data_drop_feature_by_corr,train_data_drop,test_data_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_save(re,path):\n",
    "    y_predict_df=pd.DataFrame(y_predict)\n",
    "    y_predict_df.to_csv(path,header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict=[]\n",
    "for corr_name in ['spearman','pearson']:\n",
    "    for thresholding in [0.1,0.15,0.2,0.3,0.4,0.6]:\n",
    "        #设定相关性及阈值获取需要删除的特征\n",
    "        drop_feature=get_drop_feature_by_corr(all_data_drop_1,thresholding,corr_name)\n",
    "        train_data_drop,test_data_drop=get_train_data_drop_corr(all_data_drop_1)\n",
    "        xgb_reg=XGBRegressor(n_estimators=1000,max_depth=8,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "        data=train_data_drop\n",
    "        y_data=data.iloc[:,-1]\n",
    "        X_data=data.iloc[:,:-1]\n",
    "        scores=cross_val_score(xgb_reg,X_data,y_data,scoring='neg_mean_absolute_error',cv=10)\n",
    "        para_dict.append((corr_name,thresholding,scores))\n",
    "        print(\"corr_name:%s\\tthresholding:%f\\tMAE:%s\"%(corr_name,thresholding,np.mean(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature=get_drop_feature_by_corr(all_data_drop_1,0.2,'spearman')\n",
    "all_data_drop_feature_by_corr,train_data_drop,X_test=get_train_data_drop_corr(all_data_drop_1,drop_feature)\n",
    "all_data_drop_feature_by_corr.to_csv('./re/all_data_drop_by_corr.txt',header=True,index=False)\n",
    "xgb_reg=XGBRegressor(max_depth=8,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "y_data=train_data_drop.iloc[:,-1]\n",
    "X_data=train_data_drop.iloc[:,:-1]\n",
    "xgb_reg.fit(X_data,y_data)\n",
    "y_predict=xgb_reg.predict(X_test)\n",
    "result_to_save(y_predict,'./re/y_predict_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数据进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_drop_by_corr=pd.read_csv('./re/all_data_drop_by_corr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_drop_by_corr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normal(x):\n",
    "    return (x-np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_col=all_data_drop_by_corr.columns[:-2]\n",
    "all_data_drop_by_corr[normal_col]=all_data_drop_by_corr[normal_col].apply(min_max_normal,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存归一化后的数据\n",
    "all_data_drop_by_corr.to_csv('./re/all_data_normal.txt',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取归一化后的数据并进行预测\n",
    "all_data_normal=pd.read_csv('./re/all_data_normal.txt')\n",
    "train_data,test_data=get_train_test_data(all_data_normal)\n",
    "X_train,X_validate,y_train,y_validate=split_train_validate_data(train_data,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg=XGBRegressor(max_depth=6,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "X_data=train_data.iloc[:,:-1]\n",
    "y_data=train_data['target']\n",
    "scores=cross_val_score(xgb_reg,X_data,y_data,cv=10,scoring='neg_mean_absolute_error')\n",
    "print(-np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.fit(X_data,y_data)\n",
    "y_predict=xgb_reg.predict(test_data)\n",
    "result_to_save(y_predict,'./re/y_predict_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "成绩从0.1357提高至0.1341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./re/all_data_normal.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOX-COX transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_normal=pd.read_csv('./re/all_data_normal.txt')\n",
    "cols_numeric=all_data_normal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = 6\n",
    "frows = len(cols_numeric)-1\n",
    "plt.figure(figsize=(4*fcols,4*frows))\n",
    "i=0\n",
    "\n",
    "for var in cols_numeric:\n",
    "    if var!='target' and var !='type':\n",
    "        dat = all_data_normal[[var, 'target']].dropna()\n",
    "        \n",
    "        i+=1\n",
    "        plt.subplot(frows,fcols,i)\n",
    "        sns.distplot(dat[var],fit=stats.norm);\n",
    "        plt.title(var+' Original')\n",
    "        plt.xlabel('')\n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        plt.subplot(frows,fcols,i)\n",
    "        _=stats.probplot(dat[var], plot=plt)\n",
    "        plt.title('skew='+'{:.4f}'.format(stats.skew(dat[var])))\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        \n",
    "        i+=1\n",
    "        plt.subplot(frows,fcols,i)\n",
    "        plt.plot(dat[var], dat['target'],'.',alpha=0.5)\n",
    "        plt.title('corr='+'{:.2f}'.format(np.corrcoef(dat[var], dat['target'])[0][1]))\n",
    "        \n",
    "       \n",
    "        \"\"\"\n",
    "        boxcox:\n",
    "           y = (x**lmbda - 1) / lmbda,  for lmbda > 0\n",
    "               log(x),                  for lmbda = 0\n",
    "        \"\"\"\n",
    "     \n",
    "        i+=1\n",
    "        plt.subplot(frows,fcols,i)\n",
    "        trans_var, lambda_var = stats.boxcox(dat[var].dropna()+1)\n",
    "        trans_var = min_max_normal(trans_var)      \n",
    "        sns.distplot(trans_var , fit=stats.norm);\n",
    "        plt.title(var+' Tramsformed')\n",
    "        plt.xlabel('')\n",
    "        \n",
    "        i+=1\n",
    "        plt.subplot(frows,fcols,i)\n",
    "        _=stats.probplot(trans_var, plot=plt)\n",
    "        plt.title('skew='+'{:.4f}'.format(stats.skew(trans_var)))\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        \n",
    "        i+=1\n",
    "        plt.subplot(frows,fcols,i)\n",
    "        plt.plot(trans_var, dat['target'],'.',alpha=0.5)\n",
    "        plt.title('corr='+'{:.2f}'.format(np.corrcoef(trans_var,dat['target'])[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行box-cox变换\n",
    "for feature in cols_numeric[:-2]:\n",
    "    all_data_normal[feature],_=stats.boxcox(all_data_normal[feature]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存box-cox变换后的结果\n",
    "all_data_normal.to_csv(\"./re/all_data_box_cox.txt\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_box_cox=pd.read_csv('./re/all_data_box_cox.txt')\n",
    "train_data,test_data=get_train_test_data(all_data_box_cox)\n",
    "X_train,X_validate,y_train,y_validate=split_train_validate_data(train_data,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg=XGBRegressor(max_depth=6,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "X_data=train_data.iloc[:,:-1]\n",
    "y_data=train_data['target']\n",
    "scores=cross_val_score(xgb_reg,X_data,y_data,cv=10,scoring='neg_mean_absolute_error')\n",
    "print(-np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.fit(X_data,y_data)\n",
    "y_predict=xgb_reg.predict(test_data)\n",
    "result_to_save(y_predict,'./re/y_predict_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论 对特征做box-cox变换后 分数从0.1341降为0.1342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对相关度高的特征进行多项式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_box_cox=pd.read_csv('./re/all_data_box_cox.txt')\n",
    "feature_thresholding=0.75\n",
    "all_data_box_cox_train=all_data_box_cox[all_data_box_cox['type']=='train'].drop(['type'],axis=1)\n",
    "target_corr=all_data_box_cox_train.corr('spearman')['target']\n",
    "high_relation_features=target_corr[target_corr>feature_thresholding].index[:-1]\n",
    "print(high_relation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=PolynomialFeatures(degree=2,interaction_only=False)\n",
    "poly_features=poly.fit_transform(all_data_box_cox_train[high_relation_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df=pd.DataFrame(data=poly_features,columns=poly.get_feature_names(high_relation_features)).iloc[:,1:]\n",
    "train_poly_df=poly_df.drop(labels=high_relation_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_box_cox_test=all_data_box_cox[all_data_box_cox['type']=='test'].drop(['type','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features_test=poly.transform(all_data_box_cox_test[high_relation_features])\n",
    "poly_df_test=pd.DataFrame(data=poly_features_test,columns=poly.get_feature_names(high_relation_features)).iloc[:,1:]\n",
    "poly_df_test=poly_df_test.drop(labels=high_relation_features,axis=1)\n",
    "all_poly_df=train_poly_df.append(poly_df_test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type=all_data_box_cox[['target','type']]\n",
    "all_data_box_cox=all_data_box_cox.drop(labels=['target','type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_box_cox_poly=pd.merge(all_data_box_cox,all_poly_df,left_index=True,right_index=True,how='outer')\n",
    "all_data_box_cox_poly=pd.merge(all_data_box_cox_poly,target_type,left_index=True,right_index=True,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_box_cox_poly.to_csv('./re/all_data_box_cox_poly.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对多项式特征，通过xgb训练筛选出离群数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    diff = y_pred - y_true\n",
    "    sum_sq = sum(diff**2)    \n",
    "    n = len(y_pred)   \n",
    "    \n",
    "    return np.sqrt(sum_sq/n)\n",
    "def mse(y_ture,y_pred):\n",
    "    return mean_squared_error(y_ture,y_pred)\n",
    "mse_score=make_scorer(mse,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(model, X, y, sigma=3):\n",
    "\n",
    "    # predict y values using model\n",
    "    try:\n",
    "        y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "    # if predicting fails, try fitting the model first\n",
    "    except:\n",
    "        model.fit(X,y)\n",
    "        y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "        \n",
    "    # calculate residuals between the model prediction and true y values\n",
    "    resid = y - y_pred\n",
    "    mean_resid = resid.mean()\n",
    "    std_resid = resid.std()\n",
    "\n",
    "    # calculate z statistic, define outliers to be where |z|>sigma\n",
    "    z = (resid - mean_resid)/std_resid    \n",
    "    outliers = z[abs(z)>sigma].index\n",
    "    \n",
    "    # print and plot the results\n",
    "    print('R2=',model.score(X,y))\n",
    "    print('rmse=',rmse(y, y_pred))\n",
    "    print(\"mse=\",mean_squared_error(y,y_pred))\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    print('mean of residuals:',mean_resid)\n",
    "    print('std of residuals:',std_resid)\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    print(len(outliers),'outliers:')\n",
    "    print(outliers.tolist())\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    ax_131 = plt.subplot(1,3,1)\n",
    "    plt.plot(y,y_pred,'.')\n",
    "    plt.plot(y.loc[outliers],y_pred.loc[outliers],'ro')\n",
    "    plt.legend(['Accepted','Outlier'])\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y_pred');\n",
    "\n",
    "    ax_132=plt.subplot(1,3,2)\n",
    "    plt.plot(y,y-y_pred,'.')\n",
    "    plt.plot(y.loc[outliers],y.loc[outliers]-y_pred.loc[outliers],'ro')\n",
    "    plt.legend(['Accepted','Outlier'])\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y - y_pred');\n",
    "\n",
    "    ax_133=plt.subplot(1,3,3)\n",
    "    z.plot.hist(bins=50,ax=ax_133)\n",
    "    z.loc[outliers].plot.hist(color='r',bins=50,ax=ax_133)\n",
    "    plt.legend(['Accepted','Outlier'])\n",
    "    plt.xlabel('z')\n",
    "    \n",
    "    plt.savefig('outliers.png')\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'./re/all_data_box_cox.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_box_cox=pd.read_csv('./re/all_data_box_cox_poly.txt')\n",
    "train_data,test_data=get_train_test_data(all_data_box_cox)\n",
    "X_train,X_validate,y_train,y_validate=split_train_validate_data(train_data,test_size=0.3,random_state=1)\n",
    "xgb_reg=XGBRegressor(max_depth=6,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "outliers = find_outliers(xgb_reg,train_data.iloc[:,:-1],train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_drop_out_data=all_data_box_cox.drop(labels=outliers)\n",
    "all_data_drop_out_data.to_csv('./re/all_data_drop_out_data.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=get_train_test_data(all_data_drop_out_data)\n",
    "X_train,X_validate,y_train,y_validate=split_train_validate_data(train_data,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg=XGBRegressor(max_depth=6,min_child_weight=5,eta=0.05, gamma=0.025,colsample_bytree= 0.6,subsample=0.7)\n",
    "X_data=train_data.iloc[:,:-1]\n",
    "y_data=train_data['target']\n",
    "scores=cross_val_score(xgb_reg,X_data,y_data,cv=10,scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.fit(X_data,y_data)\n",
    "y_predict=xgb_reg.predict(test_data)\n",
    "result_to_save(y_predict,'./re/y_predict_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：通过xgb筛选出离群数据，score从0.1342提高到0.1336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对xgb进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_drop_out_data=pd.read_csv('./re/all_data_drop_out_data.txt')\n",
    "train_data,test_data=get_train_test_data(all_data_drop_out_data)\n",
    "X_data=train_data.iloc[:,:-1]\n",
    "y_data=train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg=XGBRegressor(booster='gbtree',max_depth=10,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0.025,colsample_bytree= 0.9,\n",
    "                     subsample=0.1,reg_lambda=0.5,\n",
    "                     reg_alpha=0,learning_rate=0.009,\n",
    "                     n_estimators=1000)\n",
    "grid_param={\"max_depth\":[9],\n",
    "           \"min_child_weight\":[6],\n",
    "           \"subsample\":[0.1],\n",
    "           \"colsample_bytree\":[0.9],\n",
    "           \"n_estimators\":[1000],\n",
    "           \"learning_rate\":[0.006,0.007,0.008],\n",
    "           \"reg_lambda\":[0.4,0.5,0.6],\n",
    "           \"reg_alpha\":[0,0.1,0.2],\n",
    "           }\n",
    "grid_model=GridSearchCV(xgb_reg,grid_param,scoring=mse_score,cv=5)\n",
    "grid_model.fit(X_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "print(grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg=XGBRegressor(booster='gbtree',max_depth=9,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0.025,colsample_bytree= 0.9,\n",
    "                     subsample=0.1,reg_lambda=0.5,\n",
    "                     reg_alpha=0,learning_rate=0.008,\n",
    "                     n_estimators=1000)\n",
    "X_data=train_data.iloc[:,:-1]\n",
    "y_data=train_data['target']\n",
    "scores=cross_val_score(xgb_reg,X_data,y_data,cv=10,scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.fit(X_data,y_data)\n",
    "y_predict=xgb_reg.predict(test_data)\n",
    "result_to_save(y_predict,'./re/y_predict_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：经过对xgb调参score从0.1336提高到0.1251"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
